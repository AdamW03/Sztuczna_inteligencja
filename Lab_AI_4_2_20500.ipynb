{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Ey-g-9dZKaAH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "npz = np.load('Audiobooks_data_train.npz')\n",
        "\n",
        "train_inputs = npz['inputs'].astype(np.float32)\n",
        "train_targets = npz['targets'].astype(np.int32)\n",
        "\n",
        "npz = np.load('Audiobooks_data_validation.npz')\n",
        "\n",
        "validation_inputs, validation_targets = npz['inputs'].astype(np.float32), npz['targets'].astype(np.int32)\n",
        "\n",
        "npz = np.load('Audiobooks_data_test.npz')\n",
        "\n",
        "test_inputs, test_targets = npz['inputs'].astype(np.float32), npz['targets'].astype(np.int32)"
      ],
      "metadata": {
        "id": "T7kqNma6Kk_p"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 10\n",
        "output_size = 2\n",
        "#hidden_layer_size = 25\n",
        "\n",
        "#model = tf.keras.Sequential([\n",
        " #   tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
        "#    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
        " #   tf.keras.layers.Dense(hidden_layer_size, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "#    tf.keras.layers.Dense(output_size, activation='softmax')\n",
        "#])\n",
        "hidden_layer_size = 50  # Zwiększamy liczbę neuronów\n",
        "#model = tf.keras.Sequential([\n",
        "#    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
        "#    tf.keras.layers.Dropout(0.2),  # Dodajemy Dropout po pierwszej warstwie ukrytej\n",
        "#    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
        "#    tf.keras.layers.Dropout(0.2),  # Dodajemy Dropout po drugiej warstwie ukrytej\n",
        "#    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
        "#    tf.keras.layers.Dense(hidden_layer_size, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "#    tf.keras.layers.Dense(output_size, activation='softmax')\n",
        "#])\n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(input_size, 1)),\n",
        "        tf.keras.layers.MaxPooling1D(pool_size=2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(output_size, activation='softmax')\n",
        "    ])\n",
        "\n",
        "model.compile(optimizer='adamw', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9Tk-HxMLlv_",
        "outputId": "464c06a7-ec3b-41c1-e7f6-50101358cb25"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gKQNk14iO4a-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 50\n",
        "max_epochs = 200\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)\n",
        "\n",
        "model.fit(train_inputs,\n",
        "          train_targets,\n",
        "          batch_size=batch_size,\n",
        "          epochs=max_epochs,\n",
        "          callbacks=[early_stopping],\n",
        "          validation_data=(validation_inputs, validation_targets),\n",
        "          verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPHJKrqgMMBe",
        "outputId": "0b8da880-30f4-41f4-c04d-3efc585e2ea8"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5903 - loss: 0.6709 - val_accuracy: 0.6868 - val_loss: 0.6097\n",
            "Epoch 2/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6950 - loss: 0.5876 - val_accuracy: 0.6980 - val_loss: 0.5731\n",
            "Epoch 3/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7137 - loss: 0.5585 - val_accuracy: 0.7069 - val_loss: 0.5485\n",
            "Epoch 4/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7315 - loss: 0.5266 - val_accuracy: 0.7181 - val_loss: 0.5314\n",
            "Epoch 5/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7199 - loss: 0.5220 - val_accuracy: 0.7271 - val_loss: 0.5165\n",
            "Epoch 6/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7299 - loss: 0.5107 - val_accuracy: 0.7204 - val_loss: 0.5045\n",
            "Epoch 7/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7410 - loss: 0.4907 - val_accuracy: 0.7315 - val_loss: 0.5004\n",
            "Epoch 8/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7534 - loss: 0.4784 - val_accuracy: 0.7383 - val_loss: 0.4875\n",
            "Epoch 9/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7440 - loss: 0.4831 - val_accuracy: 0.7427 - val_loss: 0.4869\n",
            "Epoch 10/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7658 - loss: 0.4605 - val_accuracy: 0.7472 - val_loss: 0.4747\n",
            "Epoch 11/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7437 - loss: 0.4791 - val_accuracy: 0.7472 - val_loss: 0.4722\n",
            "Epoch 12/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7608 - loss: 0.4658 - val_accuracy: 0.7472 - val_loss: 0.4716\n",
            "Epoch 13/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7761 - loss: 0.4515 - val_accuracy: 0.7696 - val_loss: 0.4580\n",
            "Epoch 14/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7768 - loss: 0.4470 - val_accuracy: 0.7494 - val_loss: 0.4573\n",
            "Epoch 15/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7741 - loss: 0.4435 - val_accuracy: 0.7517 - val_loss: 0.4545\n",
            "Epoch 16/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7851 - loss: 0.4355 - val_accuracy: 0.7629 - val_loss: 0.4547\n",
            "Epoch 17/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7897 - loss: 0.4304 - val_accuracy: 0.7584 - val_loss: 0.4491\n",
            "Epoch 18/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7791 - loss: 0.4349 - val_accuracy: 0.7651 - val_loss: 0.4512\n",
            "Epoch 19/200\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7739 - loss: 0.4243 - val_accuracy: 0.7517 - val_loss: 0.4503\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7dfb5225c350>"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)\n",
        "print('\\mTest loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYOZBkrFNR8g",
        "outputId": "0a707fc2-e5f4-4bca-ee25-676d57f86dc3"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7951 - loss: 0.4294 \n",
            "\\mTest loss: 0.44. Test accuracy: 76.79%\n"
          ]
        }
      ]
    }
  ]
}